#!/usr/bin/env python3
"""
æµ‹è¯•å»é‡ç²¾ä¿®æµæ°´çº¿
éªŒè¯Writerçº¦æŸå‡çº§å’Œå»é‡ç²¾ä¿®åŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from llm_report_generator import LLMReportGenerator
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_dedupe_pipeline():
    """æµ‹è¯•å»é‡ç²¾ä¿®æµæ°´çº¿"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å»é‡ç²¾ä¿®æµæ°´çº¿...")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = LLMReportGenerator()
    
    # æµ‹è¯•æ•°æ®ï¼ˆåŒ…å«é‡å¤å†…å®¹ï¼‰
    student_data = {
        "name": "å¼ å°æ˜",
        "age": "14å²",
        "grade": "Grade 8",
        "gpa": "3.8/4.0",
        "academic_strengths": "æ•°å­¦ã€ç‰©ç†ã€è®¡ç®—æœºç§‘å­¦",
        "competition_achievements": "æœºå™¨äººç«èµ›çœçº§äºŒç­‰å¥–",
        "leadership_positions": "ç§‘æŠ€éƒ¨å‰¯éƒ¨é•¿",
        "project_experiences": "ç¯ä¿ä¹‰å–æ´»åŠ¨ç»„ç»‡",
        "learning_ability": "è‡ªä¸»å­¦ä¹ å’Œé—®é¢˜è§£å†³",
        "adaptability": "è·¨æ–‡åŒ–ç¯å¢ƒé€‚åº”",
        "target_schools": [
            {
                "name": "Upper Canada College",
                "scores": {"academic": 4, "activities": 4, "culture": 5, "personality": 4},
                "weights": {"academic": 0.35, "activities": 0.25, "culture": 0.2, "personality": 0.2}
            },
            {
                "name": "Havergal College", 
                "scores": {"academic": 4, "activities": 3, "culture": 4, "personality": 3},
                "weights": {"academic": 0.35, "activities": 0.25, "culture": 0.2, "personality": 0.2}
            },
            {
                "name": "St. Andrew's College",
                "scores": {"academic": 3, "activities": 4, "culture": 4, "personality": 4},
                "weights": {"academic": 0.35, "activities": 0.25, "culture": 0.2, "personality": 0.2}
            }
        ]
    }
    
    conversation_log = [
        {"role": "student", "content": "æˆ‘å–œæ¬¢ç»„ç»‡æ´»åŠ¨å’Œåšç§‘å­¦å®éªŒï¼Œç‰¹åˆ«æ˜¯æœºå™¨äººç¼–ç¨‹"},
        {"role": "parent", "content": "å­©å­åœ¨å­¦ç”Ÿä¼šç»„ç»‡è¿‡ç¯ä¿ä¹‰å–ï¼Œå±•ç°äº†å¾ˆå¥½çš„é¢†å¯¼åŠ›"},
        {"role": "student", "content": "æˆ‘å¸Œæœ›èƒ½åœ¨STEMé¢†åŸŸç»§ç»­å‘å±•ï¼Œç‰¹åˆ«æ˜¯æ•°å­¦å’Œç‰©ç†"},
        {"role": "parent", "content": "æˆ‘ä»¬å®¶åº­é‡è§†å…¨äººæ•™è‚²ï¼Œå¸Œæœ›å­©å­åœ¨å›½é™…åŒ–ç¯å¢ƒä¸­å…¨é¢å‘å±•"}
    ]
    
    try:
        # ç”ŸæˆæŠ¥å‘Šï¼ˆåŒ…å«å»é‡ç²¾ä¿®ï¼‰
        print("ğŸ“ ç”ŸæˆæŠ¥å‘Š...")
        report_result = generator.generate_report(conversation_log, student_data)
        
        print("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“Š æŠ¥å‘Šç»Ÿè®¡:")
        print(f"   - æ€»å­—æ•°: {report_result['metadata']['word_count']}")
        print(f"   - é¡µæ•°: {report_result['metadata']['page_count']}")
        
        # æ˜¾ç¤ºå»é‡ç»“æœ
        if 'dedupe_validation' in report_result:
            dedupe_val = report_result['dedupe_validation']
            print(f"ğŸ”„ å»é‡ç»“æœ:")
            print(f"   - å­—æ•°å‡å°‘: {dedupe_val['reduction_percentage']:.1f}%")
            print(f"   - ç¬¦åˆæ ‡å‡†: {dedupe_val['meets_criteria']}")
            
            if dedupe_val.get('issues'):
                print(f"   - é—®é¢˜: {', '.join(dedupe_val['issues'])}")
        
        # å¯¼å‡ºæŠ¥å‘Š
        print("\nğŸ“ å¯¼å‡ºæŠ¥å‘Š...")
        exported_files = generator.export_report(report_result, "all")
        
        print("ğŸ“‹ å¯¼å‡ºæ–‡ä»¶:")
        for format_type, file_path in exported_files.items():
            print(f"   - {format_type}: {file_path}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        print("\nğŸ“– æŠ¥å‘Šå†…å®¹é¢„è§ˆ:")
        content_lines = report_result['content'].split('\n')
        for i, line in enumerate(content_lines[:20]):  # æ˜¾ç¤ºå‰20è¡Œ
            if line.strip():
                print(f"   {line}")
        
        if len(content_lines) > 20:
            print(f"   ... (è¿˜æœ‰ {len(content_lines) - 20} è¡Œ)")
        
        print("\nğŸ‰ å»é‡ç²¾ä¿®æµæ°´çº¿æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise

def test_dedupe_module_only():
    """å•ç‹¬æµ‹è¯•å»é‡æ¨¡å—"""
    print("ğŸ§ª å•ç‹¬æµ‹è¯•å»é‡æ¨¡å—...")
    
    from dedupe import DedupeAndPolish
    
    dedupe = DedupeAndPolish()
    
    # æµ‹è¯•æ–‡æœ¬ï¼ˆåŒ…å«é‡å¤å†…å®¹ï¼‰
    test_text = """
    å®¶åº­ä¸å­¦ç”ŸèƒŒæ™¯

    å¼ å°æ˜æ˜¯ä¸€å14å²çš„å…«å¹´çº§å­¦ç”Ÿï¼Œåœ¨æ•°å­¦ã€ç‰©ç†å’Œè®¡ç®—æœºç§‘å­¦æ–¹é¢è¡¨ç°çªå‡ºã€‚ä»–çš„GPAä¸º3.8/4.0ï¼Œåœ¨æœºå™¨äººç«èµ›ä¸­è·å¾—çœçº§äºŒç­‰å¥–ã€‚ä½œä¸ºç§‘æŠ€éƒ¨å‰¯éƒ¨é•¿ï¼Œä»–å±•ç°äº†å‡ºè‰²çš„é¢†å¯¼åŠ›å’Œç»„ç»‡èƒ½åŠ›ã€‚

    å­¦æ ¡ç”³è¯·å®šä½

    åŸºäºå¼ å°æ˜çš„å­¦æœ¯ä¼˜åŠ¿å’Œå®¶åº­ä»·å€¼è§‚ï¼Œæˆ‘ä»¬æ¨èç”³è¯·å¤šä¼¦å¤šåœ°åŒºçš„é¡¶çº§ç§ç«‹å­¦æ ¡ã€‚è¿™äº›å­¦æ ¡åœ¨å­¦æœ¯å“è¶Šã€é¢†å¯¼åŠ›åŸ¹å…»ã€æ ¡å‹ç½‘ç»œå¼ºå¤§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

    å­¦ç”Ÿâ€”å­¦æ ¡åŒ¹é…åº¦

    å¯¹äºUpper Canada Collegeï¼Œå¼ å°æ˜åœ¨å­¦æœ¯èƒ½åŠ›æ–¹é¢è¡¨ç°çªå‡ºï¼Œä¸å­¦æ ¡ç‰¹è‰²é«˜åº¦å¥‘åˆã€‚è¯¥æ ¡çš„STEMé¡¹ç›®ä¸°å¯Œï¼Œèƒ½å¤Ÿå……åˆ†å‘æŒ¥å¼ å°æ˜çš„æ•°å­¦å’Œç‰©ç†ä¸“é•¿ã€‚æ¨èç†ç”±åŒ…æ‹¬ï¼šå­¦æœ¯å“è¶Šã€é¢†å¯¼åŠ›åŸ¹å…»ã€æ ¡å‹ç½‘ç»œå¼ºå¤§ã€‚æ½œåœ¨æŒ‘æˆ˜æ˜¯ç«äº‰æ¿€çƒˆï¼Œéœ€è¦æ›´å¼ºçš„è‹±è¯­èƒ½åŠ›ã€‚

    å¯¹äºHavergal Collegeï¼Œå¼ å°æ˜åŒæ ·åœ¨å­¦æœ¯èƒ½åŠ›æ–¹é¢è¡¨ç°çªå‡ºï¼Œä¸å­¦æ ¡ç‰¹è‰²é«˜åº¦å¥‘åˆã€‚è¯¥æ ¡æ³¨é‡å…¨äººæ•™è‚²ç†å¿µï¼Œä¸å¼ å°æ˜çš„å®¶åº­ä»·å€¼è§‚åŒ¹é…ã€‚æ¨èç†ç”±åŒ…æ‹¬ï¼šå­¦æœ¯å“è¶Šã€é¢†å¯¼åŠ›åŸ¹å…»ã€æ ¡å‹ç½‘ç»œå¼ºå¤§ã€‚æ½œåœ¨æŒ‘æˆ˜æ˜¯ç”³è¯·éš¾åº¦è¾ƒé«˜ã€‚

    å¯¹äºSt. Andrew's Collegeï¼Œå¼ å°æ˜åœ¨å­¦æœ¯èƒ½åŠ›æ–¹é¢è¡¨ç°çªå‡ºï¼Œä¸å­¦æ ¡ç‰¹è‰²é«˜åº¦å¥‘åˆã€‚è¯¥æ ¡çš„ä¼ ç»Ÿä»·å€¼è§‚ä¸å¼ å°æ˜çš„å®¶åº­èƒŒæ™¯åŒ¹é…ã€‚æ¨èç†ç”±åŒ…æ‹¬ï¼šå­¦æœ¯å“è¶Šã€é¢†å¯¼åŠ›åŸ¹å…»ã€æ ¡å‹ç½‘ç»œå¼ºå¤§ã€‚æ½œåœ¨æŒ‘æˆ˜æ˜¯éœ€è¦é€‚åº”å¯„å®¿ç”Ÿæ´»ã€‚

    å­¦æœ¯ä¸è¯¾å¤–å‡†å¤‡

    åœ¨å­¦æœ¯å‡†å¤‡æ–¹é¢ï¼Œå»ºè®®å¼ å°æ˜åŠ å¼ºè‹±è¯­å†™ä½œèƒ½åŠ›ï¼Œä¿æŒSTEMä¼˜åŠ¿ã€‚åœ¨è¯¾å¤–æ´»åŠ¨æ–¹é¢ï¼Œå»ºè®®å‚ä¸æ›´å¤šSTEMç«èµ›ï¼Œå‘å±•é¢†å¯¼åŠ›ã€‚åœ¨è€ƒè¯•å‡†å¤‡æ–¹é¢ï¼ŒSSATç›®æ ‡90th percentileä»¥ä¸Šã€‚

    ç”³è¯·æµç¨‹ä¸ä¸ªæ€§åŒ–ç­–ç•¥

    ç”³è¯·æ—¶é—´çº¿åŒ…æ‹¬ï¼š10æœˆå®ŒæˆSSATè€ƒè¯•ï¼Œ11æœˆæäº¤ç”³è¯·ææ–™ï¼Œ12æœˆå‚åŠ é¢è¯•ã€‚ä¸ªæ€§åŒ–ç­–ç•¥åŒ…æ‹¬ï¼šçªå‡ºé¢†å¯¼åŠ›ï¼Œå±•ç°STEMä¸“é•¿ï¼Œå¼ºè°ƒç¤¾åŒºæœåŠ¡ã€‚

    å½•å–åå»¶ä¼¸å»ºè®®

    å½•å–åå»ºè®®ï¼šæå‰äº†è§£å­¦æ ¡æ–‡åŒ–ï¼Œå‡†å¤‡å­¦æœ¯è¡”æ¥ï¼Œå»ºç«‹ç¤¾äº¤ç½‘ç»œã€‚æˆ‘ä»¬çš„ä¸“ä¸šä»·å€¼åœ¨äºæä¾›å…¨æ–¹ä½çš„ç”³è¯·æŒ‡å¯¼ï¼Œç¡®ä¿æˆåŠŸä¿éšœã€‚
    """
    
    ctx = {
        "sectionAnchors": ["å®¶åº­ä¸å­¦ç”ŸèƒŒæ™¯", "å­¦æ ¡ç”³è¯·å®šä½", "å­¦ç”Ÿâ€”å­¦æ ¡åŒ¹é…åº¦", 
                         "å­¦æœ¯ä¸è¯¾å¤–å‡†å¤‡", "ç”³è¯·æµç¨‹ä¸ä¸ªæ€§åŒ–ç­–ç•¥", "å½•å–åå»¶ä¼¸å»ºè®®"]
    }
    
    # æ‰§è¡Œå»é‡
    result = dedupe.dedupe_and_polish(test_text, ctx)
    
    # éªŒè¯ç»“æœ
    validation = dedupe.validate_dedupe_result(test_text, result)
    
    print("ğŸ“Š å»é‡ç»“æœ:")
    print(f"   - åŸæ–‡é•¿åº¦: {validation['original_length']}")
    print(f"   - å»é‡åé•¿åº¦: {validation['deduped_length']}")
    print(f"   - å‡å°‘å­—æ•°: {validation['length_reduction']}")
    print(f"   - å‡å°‘æ¯”ä¾‹: {validation['reduction_percentage']:.1f}%")
    print(f"   - ç¬¦åˆæ ‡å‡†: {validation['meets_criteria']}")
    
    if validation['issues']:
        print("   - é—®é¢˜:")
        for issue in validation['issues']:
            print(f"     * {issue}")
    
    print("\nğŸ“– å»é‡åå†…å®¹é¢„è§ˆ:")
    result_lines = result.split('\n')
    for i, line in enumerate(result_lines[:15]):  # æ˜¾ç¤ºå‰15è¡Œ
        if line.strip():
            print(f"   {line}")
    
    if len(result_lines) > 15:
        print(f"   ... (è¿˜æœ‰ {len(result_lines) - 15} è¡Œ)")
    
    print("\nâœ… å»é‡æ¨¡å—æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    print("ğŸš€ å»é‡ç²¾ä¿®æµæ°´çº¿æµ‹è¯•")
    print("="*50)
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å¼
    if len(sys.argv) > 1 and sys.argv[1] == "--dedupe-only":
        test_dedupe_module_only()
    else:
        test_dedupe_pipeline()
    
    print("\n" + "="*50)
    print("ğŸ¯ æµ‹è¯•å®Œæˆï¼")
